Что-то похожее на черновик по SVD - разложению.


**SVD - разложение **

---

Сингулярное или SVD разложение, это представление матрицы $A_{m\times{n}}$ ,ввиде произведения трёх матриц специального вида
$\hspace{5em} A_{m\times{n}} = U_{m\times{m}} \cdot S_{m\times{n}} \cdot V_{n\times{n}}^T$
 

, где  $U$ и $V$ -- унитарные матрицы --- матрицы удовлетворяющие уравнению $\hspace{5em}$ $A^*A = AA^* = I$ 
где $M^*$ --- операция сопряжения, обозначающая последовательно применённые операции транспонирования и комплексного сопряжения всех элементов матрицы.
$\hspace{5em}$$M^* = \overline{M^T}$

$S$ --- диагональная матрица, вида $S = diag(\sigma_1, \dots, \sigma_r, 0\:, \dots, 0) $

- элементы $\sigma_i$ , называются сингулярными числами матрицы $A$
- строки $u_i$ ,матрицы $U$, называются левыми сингулярными векторами матрицы $A$
- столбцы $v_i$ ,матрицы $V$, называются правыми сингулярными векторами матрицы $A$

---

**Свойства сингулярного разложения[^1]**

1. Существует и единственно (с точностью до порядка и знаков сингулярных чисел и векторов), для любой матрицы $A$

2.  Левые и правые сингулярные векторы, являются собственными векторами матриц  $AA^T$ и $A^TA$ соответственно. 

3.  Сингулярные числа являются квадратами соответственных собственных чисел матриц  $AA^T$ и $A^TA$ 

4.  Количество ненулевых собственных чисел равно рангу матрицы $A$

5. Возьмём матрицу $A_k$, такую что $A_k = U*S_k*V^T$, где $S_k$,  это матрица $S$, в которой $r-k$ наименьших сингулярных чисел заменены на нули.

 Тогда $A_k$, это матрица  с рангом $k$, лучше всего приближающая матрицу $A$, по норме Фробениуса.
  или, если переписать в кванторах

 $\hspace{5em}$ $\min\limits_{B \:: rank(B) = k} ||A-B||_2 = ||A-A_k||_2$
 
  Норма Фробениуса матрицы $A$ или $||A||_2$ равна
 $\hspace{5em}$$||A||_2 = \: \sqrt{\sum\limits_{i = 1}^m \sum\limits_{j=1}^n a_{ij}^2} $




---
**Доказательство свойств **


Пусть $A = U \cdot S \cdot V^*$ тогда $AA^T = U \cdot S^2 \cdot U^*$ и $A^TA = V \cdot S^2 \cdot V^*$.
Тогда так как $AA^T$ и $AA^T$ симметричные квадратные матрицы, размеров $m\times{m}$ и $n\times{n}$ соответственно и мы знаем, что квадратные симметричные матрицы, всегда дигонализируемы, то есть представимы в виде произведения матриц $H \cdot Z \cdot H^T$, где $H$ - унитарная матрица из собственных векторов, а $Z = diag(\lambda_1,\dots, \lambda_r, 0 ,\dots, 0)$ , где $\lambda_i$ собственные числа. Это оказывает свойства [2] и [3]

Также мы знаем что ранг матрицы $A$ совпадает в рангом матриц $AA^T$  и $A^TA$ , а их ранг, равен числу ненулевых собственных чисел, которое по свойству [3] совпадает с количеством ненулевых сингулярных чисел. Это доказывает свойство [4]

---

**Пример**

Пусть $A  $

 \begin{pmatrix}
1 & 2 & 3\\
3 & 1 & 5\\
0 & 5 & 4 \\
 \end{pmatrix}
 
Тогда 
$
\begin{array}{c|c|c}
U & S & V \\
\hline
\begin{array}{rrr}
    -0.43 & -0.02 & -0.90 \\
-0.60 & -0.74 &  0.30 \\
-0.68 &  0.67 &  0.30 \\
  \end{array} &
  \begin{array}{rrr}
  8.78 &  0 &  0 \\
0 &  3.58 &  0 \\
0 &  0 &  0 \\
  \end{array}&
  \begin{array}{rrr}
    -0.25 & -0.63 & -0.74 \\
-0.55 &  0.72 & -0.42 \\
-0.80 & -0.30 &  0.53 \\
  \end{array}
 \end{array}
$

Как мы видим, у матрицы $S$ , два ненулевых сингулярных числа. По свойству [4], это значит $rank(A) = 2$
Это можно проверить и по другому. Можно заметить что $(2) + (3) = 3*(1) $ где $(i)$ это $i$ строчка матрицы $A$.  Это значит что $rank(A) = 2$

$ 
\begin{array}{c|c}
AA^T & A^TA \\
\hline
\begin{array}{ccc}
    26 & 9 & 5 \\
    9 & 42 & 1 \\
    5 &1 & 1  \\
  \end{array} &
  \begin{array}{ccc}
    17 & 20 & 9 \\
    20 & 25 & 5 \\
    9 & 5 & 27  \\
  \end{array} \\
\end{array}
$


---
**Применения сингулярного разложения**

1. Решение задачи наименьших квадратов.
<br> 
Введем сначала понятия псевдорешения и псевдообратной матрицых[^2].
<br>
$\hspace{5em}$ Пусть у нас есть матричное уравнение $Ax = b$
$\hspace{5em}$ Если $A$ обратима, то решение этого уравнения $x = A^{-1}b$
$\hspace{5em}$ Но если $A$ необратима, то решения не существует или их бесконечно много
$\hspace{5em}$ Но мы можем найти так называемое псевдорешение, то есть такое $\tilde{x}$, что
$\hspace{5em}$ $\tilde{x} = \underset{x}{\mathrm{argmin}}||Ax-b||_2$
$\hspace{5em}$ Доказано что $\tilde{x} = A^+b = V \cdot S^+ \cdot U^T \cdot b$
$\hspace{5em}$ Где $A^+$ - называется псевдообратной к матрице $A$
$\hspace{5em}$ Матрицы $U$, $S$ и $V$ это сингулярное разложение матрицы $A$
$\hspace{5em}$ Матрица  $S^+ = diag(^1/_{\sigma_1}, \dots, ^1/_{\sigma_r}, 0 \dots, 0)$
<br>
Для того чтобы продемонстрировать метод наименьших квадратов, я сконструирую пример.
<br>
Возмём параболу, имеющую уравнение $3.15 + 1.59*x + 3.45*x^2$ (параметры взяты случайно)
Возьмём её значения в случайных целочисленных точках $[8, 6, 9, 4, 0]$
И добавим к ней равномерно распределённый шум с средним $0.5$
<br>
Получим матрицу $A$ вот такого вида
<br>$
\left\( \begin{array}{rr}
8.0 & 237.05 \\
6.0 & 136.98 \\
9.0 & 297.17 \\
4.0 & 64.93 \\
0.0 & 3.65 \\
\end{array}\right\)
$
<br>
, где $i$-тая строка вида $(x_i , y_i)$  , соответствует точке с координатами $(x_i,y_i)$.
Пусть мы хотим найти прямую $y = a + bx$ , которая лучше всего описывает эти точки.
<br>
То есть такую что $(a,b) =  \underset{a,b}{\mathrm{argmin}}\sum\limits_{i=1}^n|y_i - a - bx_i|$
<br>
Такую задачу можно переписать как поиск псведорешения матричного уравнения $Bk = y$ , 
где $k = (a,b)^T$ , а $y = (y_1,\dots,y_n)^T$, а $B$ - матрица следующего вида
<br>
$
\left\( \begin{array}{rr}
1 & x_1 \\
\vdots & \vdots \\
1 & x_n \\
\end{array}\right\)
$
<br>
В нашем случае матрица $B$ будет равна
<br>
$
\left\( \begin{array}{cc}
1.0 & 8.0 \\
1.0 & 6.0 \\
1.0 & 9.0 \\
1.0 & 4.0 \\
1.0 & 0.0 \\
\end{array}\right\)
$
<br>
Матрица $B$, прямоугольная, а значит $rank(B) <= \min(m.n) <= 2$ , и так как у неё $10$ строк, 
это не полноранговая матрица, поэтому мы сможем найти только псевдорешение.
<br>
Тогда $SVD$ разложение матрицы $B$ будет
<br>$
\begin{array}{c|c|c}
U & S & V \\
\hline
\begin{array}{rrrrr}
0.57 & -0.09 & -0.76 & -0.2 & 0.24 \\
0.43 & 0.15 & 0.16 & -0.37 & -0.79 \\
0.64 & -0.21 & 0.62 & 0.05 & 0.4 \\
0.29 & 0.39 & -0.12 & 0.84 & -0.19 \\
0.01 & 0.88 & 0.1 & -0.32 & 0.34 \\
  \end{array} &
  \begin{array}{rr}
14.17 & 0.0 \\
0.0 & 1.13 \\
0 & 0 \\
0 & 0 \\
0 & 0 \\
  \end{array}&
  \begin{array}{rr}
0.14 & 0.99 \\
0.99 & -0.14 \\
  \end{array}
 \end{array}
$
<br>
Тогда псевдобратная матрица к матрице $B$ будет равна
<br>$
\begin{array}{c}
B^+ \\
\hline
  \begin{array}{rrrrr}
-0.07 & 0.14 & -0.18 & 0.35 & 0.77 \\
0.05 & 0.01 & 0.07 & -0.03 & -0.11 \\
  \end{array}
 \end{array}
$
<br>
Перемножая $B^+ \cdot y = (-26.88, 32.38)^T$
Значит нужная нам прямая имеет уравнение $y = -26.88 - 32.88x$
<img src="https://pp.vk.me/c638622/v638622325/c479/aaSgo5LMocs.jpg">
Как мы видим на рисунке прямая не очень хорошо описывает точки. 
Попробуем подобрать параболу.
То есть найти псведорешение матричного уравнения $Bk = y$ , где $k = (a,b,c)^T$ , а $y = (y_1,\dots,y_n)^T$, а $B$ - матрица следующего вида
<br>$
\left\( \begin{array}{rrr}
1 & x_1 & x_1^2\\
\vdots & \vdots & \vdots\\
1 & x_n & x_n^2\\
\end{array}\right\)
$
<br>
В этом случае матрица $B$ будет равна
<br>$
\left\( \begin{array}{ccс}
1.0 & 8.0 & 64.0 \\
1.0 & 6.0 & 36.0 \\
1.0 & 9.0 & 81.0 \\
1.0 & 4.0 & 16.0 \\
1.0 & 0.0 & 0.0 \\
\end{array}\right\)
$
<br>
Тогда $SVD$ разложение матрицы $B$ будет
<br>$
\begin{array}{c|c|c}
U & S & V \\
\hline
\begin{array}{rrrrr}
-0.58 & 0.0 & 0.04 & -0.44 & 0.68 \\
-0.33 & 0.54 & 0.14 & -0.48 & -0.6 \\
-0.73 & -0.39 & -0.1 & 0.44 & -0.33 \\
-0.15 & 0.74 & 0.01 & 0.61 & 0.26 \\
0.0 & 0.12 & -0.98 & -0.13 & -0.02 \\
  \end{array} &
  \begin{array}{rrr}
111.36 & 0.0 & 0.0 \\
0.0 & 2.88 & 0.0 \\
0.0 & 0.0 & 0.95 \\
0 & 0 & 0 \\
0 & 0 & 0\\
  \end{array}&
  \begin{array}{rrr}
-0.02 & -0.12 & -0.99 \\
0.35 & 0.93 & -0.12 \\
-0.94 & 0.35 & -0.03 \\
  \end{array}
 \end{array}
$
<br>
Тогда псевдобратная матрица к матрице $B$ будет равна
<br>$
\begin{array}{c}
B^+ \\
\hline
  \begin{array}{rrrrr}
-0.04 & -0.08 & 0.05 & 0.08 & 0.98 \\
0.02 & 0.23 & -0.16 & 0.24 & -0.32 \\
0.0 & -0.02 & 0.03 & -0.03 & 0.02 \\
  \end{array}
 \end{array}
$
<br>
Перемножая $B^+ \cdot y = (3.65, 1.46, 3.46)^T$
Значит нужная нам парабола имеет уравнение $y = 3.65 + 1.46x + 3.46x^2$
Как мы видим на рисунке, парабола очень хорошо аппроксимирует точки.
Также можно заметить, что получившеся коэффициенты, немного отличаются от тех помощью которых мы генерировали параболу. Но это можно объяснить тем что мы добавили к точкам шум.
<img src="https://pp.vk.me/c638622/v638622325/c471/iXvMmpj_3Zc.jpg">

2. Подавление шумов на изображении.
<br>
В этом пункте, говоря о SVD  разложении изображения, я буду подразумевать, SVD  разложения каждого из его каналов (R, G , B).
Если мы добавляем к изображению небольшой шум, то его сингулярные числа меняются ненамного, так как SVD разложение это непрерывное отображение матриц.
Если наше изображение это фотография, то достаточно часто все его собственные числа будут достаточно большими, и при зашумлении такого изображения часто появляются новые очень близкие к нулю сингулярные числа, а старые меняются совсем немного. Таким образом, мы можем очищать изображения от шума, реконструируя изображение по его достаточно большим сингулярным числам.
Ниже приведен пример.
<br>
<table>
<tr>
	<th> Оригинальное</th>
	<th> Зашумлённое  </th>
	<th> Восстановленное </th>
</tr>
<tr>
<td>
	<img src="https://pp.vk.me/c638621/v638621325/113ec/z1-0Rxe1GVE.jpg" alt="Original Image>
</td>
<td>
	<img src="https://pp.vk.me/c638621/v638621325/113fb/Kg1v0UVU3-w.jpg" alt="Noised Image>
</td>
<td>
	<img src="https://pp.vk.me/c638621/v638621325/11402/t8w-9QRQ_Qw.jpg" alt="Restored Image>
</td>
</tr>
</table>
<br>
3. Уменьшение размерности данных.
<br>
4. Восстановление утраченных данных.

---
**Алгоритмы для вычисления сингулярного разложения **

<table border="2" align="right">
  <tr border="2">
    <th >Algorithm's name</th>
    <th width="150">Class</th>
    <th width="150">Complexity</th>
    <th width="150">Numerical stability</th>
    <th width="150">Compute<br>  what?</th>
    <th >Link</th>
  </tr>
  <tr>
  <td >1. Convert to bidiagonal  (Householder)  
  <br/><br/>  2. Found roots of the charasterictic polynomial  (implicit inverse power  method) 
  <br/> <br/> 3. Found singular vectors (back propagate)    </td>
    <td >Exact</td>
    <td >$O(2mn^2+2nm^2)$</td>
    <td >Good</td>
    <td >Full  Matrices</td>
    <td> 
    <a href="https://www.quora.com/Whats-the-time-complexity-of-NumPys-SVD-method"> link </a>
    </td>
  </tr>
  <tr >
    <td >Jacobi rotations</td>
    <td >Iterative</td>
    <td >???</td>
    <td >Very  Good</td>
    <td >Full  Matrices</td>
	<td>
	<a href="http://www.ams.org/journals/tran/1960-094-01/S0002-9947-1960-0109825-2/S0002-9947-1960-0109825-2.pdf">link</a>
    </td>
  </tr>
  <tr>
    <td >1. Symmetric QR decomposition of $A^TA$  </td>
    <td ></td>
    <td ></td>
    <td ></td>
    <td ></td>
    <td ></td>
  </tr>
  <tr>
    <td >(Monte Carlo)  <br/>  k - rows</td>
    <td >Iterative</td>
    <td >$O(m*n*log(k)$</td>
    <td >Good</td>
    <td >k-th approximation     of full matricies</td>
    <td >
    <a href="https://arxiv.org/pdf/0909.4061v2.pdf"> link</a>
    </td>
  </tr>
  <tr>
    <td >LAPACK ( xBDSCR) <br/>   on bidiagonal matrix  n×n</td>
    <td >Exact</td>
    <td >$O(n*k)$</td>
    <td >Good</td>
    <td >k-th  approximation     of full matricies</td>
	<td>
	<a href="http://www.netlib.org/lapack/lawnspdf/lawn166.pdf">link</a>
    </td>
  </tr>
</table>


**Литература**

[^1]: Курс Аналитической геометрии и линейной алгебры. Беклемишев Д. В. (с. 234)

[^2]: Дополнительные главы линейной алгебры. Беклемишев  Д. В. (с. 187)